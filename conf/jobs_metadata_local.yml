wordcount:  # showcases raws pyspark, full flexibility, no helper functions
  inputs:
    lines: {'path':"data/wordcount/input/sample_text.txt", 'type':'txt'}
    # lines: {'path':"data/worksi/input/worksi_chat", 'type':'parquet'}
  output: {'path':'data/wordcount/output/{now}/', 'type':'txt'}

ex2_frameworked_job:  # showcases frameworked pyspark ops (can mix sql, df and rdd ops)
  inputs:
    # some_events: {'path':"data/bogus_data/inputs/events_log.csv.gz", 'type':'csv'}
    some_events: {'path':"data/bogus_data/inputs/{latest}/events_log.csv.gz", 'type':'csv'}
    # other_events: {'path':"data/bogus_data/inputs/events_log.csv.gz", 'type':'csv'}
    other_events: {'path':"data/bogus_data/inputs/{latest}/events_log.csv.gz", 'type':'csv'}
  output: {'path':'data/bogus_data/output/{now}/', 'type':'csv'}

ex1_full_sql_job:  # showcases 100% sql job, easier but less flexible
  inputs:
    some_events: {'path':"data/bogus_data/inputs/{latest}/events_log.csv.gz", 'type':'csv'}
    other_events: {'path':"data/bogus_data/inputs/{latest}/events_log.csv.gz", 'type':'csv'}
  output: {'path':'data/bogus_data/output_sql/{now}/', 'type':'csv'}
